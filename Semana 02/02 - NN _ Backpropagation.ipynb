{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G1ivCcAyJxSj"
      },
      "source": [
        "<img src=\"https://raw.githubusercontent.com/alan-barzilay/NLPortugues/master/imagens/logo_nlportugues.png\"   width=\"150\" align=\"right\">\n",
        "\n",
        "\n",
        "# Lista 2 - NN & Backpropagation\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "_________________________________________\n",
        "\n",
        "Antes de começar o exercício,  não se esqueça de instalar todos os pacotes necessários para a sua execução.  "
      ],
      "metadata": {
        "id": "5EbG7paYJ-sT"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "hF9mL2iuJxSl",
        "outputId": "177a0d18-ef7a-469f-e343-7fcb15e6dca9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'2.18.0'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 1
        }
      ],
      "source": [
        "import tensorflow as tf\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from tensorflow import keras\n",
        "from sklearn.model_selection import train_test_split\n",
        "%matplotlib inline\n",
        "tf.__version__"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4U58nHrAJxSn"
      },
      "source": [
        "## Perceptron\n",
        "\n",
        "O perceptron é uma \"rede neural\" de um só neurônio.  No nosso caso, temos a rede mais simples possível, com uma só entrada e uma só saída, sem ativação.\n",
        "\n",
        "Temos 100 dados que serão usados para treinar 300 épocas do percéptron.\n",
        "\n",
        "Vamos utilizar o modelo percéptron para aprender uma simples regressão linear, o objetivo é faze-lo aprender uma simples equação linear e tambem se acostumar com a sintaxe e funcionamento do TensorFlow\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "id": "YElbceStJxSn"
      },
      "outputs": [],
      "source": [
        "def f1(x):\n",
        "    '''\n",
        "    Funcao a ser aprendida\n",
        "    '''\n",
        "    return 5 + 10*x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {
        "id": "JDqMORncJxSo",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "outputId": "5a6d0bfa-ff5a-4ff1-8c37-b18180c1edd7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "100 xs= [ 0.          0.1010101   0.2020202   0.3030303   0.4040404   0.50505051\n",
            "  0.60606061  0.70707071  0.80808081  0.90909091  1.01010101  1.11111111\n",
            "  1.21212121  1.31313131  1.41414141  1.51515152  1.61616162  1.71717172\n",
            "  1.81818182  1.91919192  2.02020202  2.12121212  2.22222222  2.32323232\n",
            "  2.42424242  2.52525253  2.62626263  2.72727273  2.82828283  2.92929293\n",
            "  3.03030303  3.13131313  3.23232323  3.33333333  3.43434343  3.53535354\n",
            "  3.63636364  3.73737374  3.83838384  3.93939394  4.04040404  4.14141414\n",
            "  4.24242424  4.34343434  4.44444444  4.54545455  4.64646465  4.74747475\n",
            "  4.84848485  4.94949495  5.05050505  5.15151515  5.25252525  5.35353535\n",
            "  5.45454545  5.55555556  5.65656566  5.75757576  5.85858586  5.95959596\n",
            "  6.06060606  6.16161616  6.26262626  6.36363636  6.46464646  6.56565657\n",
            "  6.66666667  6.76767677  6.86868687  6.96969697  7.07070707  7.17171717\n",
            "  7.27272727  7.37373737  7.47474747  7.57575758  7.67676768  7.77777778\n",
            "  7.87878788  7.97979798  8.08080808  8.18181818  8.28282828  8.38383838\n",
            "  8.48484848  8.58585859  8.68686869  8.78787879  8.88888889  8.98989899\n",
            "  9.09090909  9.19191919  9.29292929  9.39393939  9.49494949  9.5959596\n",
            "  9.6969697   9.7979798   9.8989899  10.        ]\n",
            "100 ys= [  5.           6.01010101   7.02020202   8.03030303   9.04040404\n",
            "  10.05050505  11.06060606  12.07070707  13.08080808  14.09090909\n",
            "  15.1010101   16.11111111  17.12121212  18.13131313  19.14141414\n",
            "  20.15151515  21.16161616  22.17171717  23.18181818  24.19191919\n",
            "  25.2020202   26.21212121  27.22222222  28.23232323  29.24242424\n",
            "  30.25252525  31.26262626  32.27272727  33.28282828  34.29292929\n",
            "  35.3030303   36.31313131  37.32323232  38.33333333  39.34343434\n",
            "  40.35353535  41.36363636  42.37373737  43.38383838  44.39393939\n",
            "  45.4040404   46.41414141  47.42424242  48.43434343  49.44444444\n",
            "  50.45454545  51.46464646  52.47474747  53.48484848  54.49494949\n",
            "  55.50505051  56.51515152  57.52525253  58.53535354  59.54545455\n",
            "  60.55555556  61.56565657  62.57575758  63.58585859  64.5959596\n",
            "  65.60606061  66.61616162  67.62626263  68.63636364  69.64646465\n",
            "  70.65656566  71.66666667  72.67676768  73.68686869  74.6969697\n",
            "  75.70707071  76.71717172  77.72727273  78.73737374  79.74747475\n",
            "  80.75757576  81.76767677  82.77777778  83.78787879  84.7979798\n",
            "  85.80808081  86.81818182  87.82828283  88.83838384  89.84848485\n",
            "  90.85858586  91.86868687  92.87878788  93.88888889  94.8989899\n",
            "  95.90909091  96.91919192  97.92929293  98.93939394  99.94949495\n",
            " 100.95959596 101.96969697 102.97979798 103.98989899 105.        ]\n"
          ]
        }
      ],
      "source": [
        "xs = np.linspace(0,10,100)  # gera 100 valores no intervalo [0.10]\n",
        "ys = f1(xs)                 # computa o valor de f1 nestes 100 valores\n",
        "print(len(xs), \"xs=\", xs)\n",
        "print(len(ys), \"ys=\", ys)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {
        "scrolled": true,
        "id": "0FPmfqsRJxSp",
        "collapsed": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "79d95d10-8953-4561-94ef-0d74503e45ce"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/300\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 3085.8318  \n",
            "Epoch 2/300\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 3153.8201 \n",
            "Epoch 3/300\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 3169.7983 \n",
            "Epoch 4/300\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 3158.8901 \n",
            "Epoch 5/300\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 3224.0833 \n",
            "Epoch 6/300\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 3162.5862 \n",
            "Epoch 7/300\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 3179.2798 \n",
            "Epoch 8/300\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 2963.3914 \n",
            "Epoch 9/300\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 3293.2085 \n",
            "Epoch 10/300\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 2986.4944\n",
            "Epoch 11/300\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 3164.0757 \n",
            "Epoch 12/300\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 3207.0618 \n",
            "Epoch 13/300\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 3166.9629 \n",
            "Epoch 14/300\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 3278.5627 \n",
            "Epoch 15/300\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 3257.4031 \n",
            "Epoch 16/300\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 3313.0186 \n",
            "Epoch 17/300\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 3173.6350 \n",
            "Epoch 18/300\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 3187.6211 \n",
            "Epoch 19/300\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 3211.2983 \n",
            "Epoch 20/300\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 3341.7683 \n",
            "Epoch 21/300\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 3245.1567 \n",
            "Epoch 22/300\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 3108.0471 \n",
            "Epoch 23/300\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 3035.9397 \n",
            "Epoch 24/300\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 3105.0107 \n",
            "Epoch 25/300\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 3141.7222 \n",
            "Epoch 26/300\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 3266.4636 \n",
            "Epoch 27/300\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 3065.7522 \n",
            "Epoch 28/300\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 3215.8491 \n",
            "Epoch 29/300\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 3059.1013 \n",
            "Epoch 30/300\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 3281.6379 \n",
            "Epoch 31/300\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 3081.8779 \n",
            "Epoch 32/300\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 3050.5979 \n",
            "Epoch 33/300\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 3174.9829\n",
            "Epoch 34/300\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 3198.2019 \n",
            "Epoch 35/300\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 2997.6272\n",
            "Epoch 36/300\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 3050.7742 \n",
            "Epoch 37/300\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 3154.6274 \n",
            "Epoch 38/300\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 3144.0847 \n",
            "Epoch 39/300\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 3045.9294 \n",
            "Epoch 40/300\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 3139.4597 \n",
            "Epoch 41/300\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 3279.6121 \n",
            "Epoch 42/300\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 3020.8716 \n",
            "Epoch 43/300\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 3039.2937 \n",
            "Epoch 44/300\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 3265.6653 \n",
            "Epoch 45/300\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 2926.2314\n",
            "Epoch 46/300\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 3082.8914  \n",
            "Epoch 47/300\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 3122.5920 \n",
            "Epoch 48/300\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 3099.5107 \n",
            "Epoch 49/300\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 3041.2136 \n",
            "Epoch 50/300\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 3039.3818 \n",
            "Epoch 51/300\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 2880.0811 \n",
            "Epoch 52/300\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 2998.5347 \n",
            "Epoch 53/300\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 2914.2581\n",
            "Epoch 54/300\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 3108.0320 \n",
            "Epoch 55/300\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 3060.8857\n",
            "Epoch 56/300\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 2994.4783 \n",
            "Epoch 57/300\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 2981.1235\n",
            "Epoch 58/300\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 3101.1782 \n",
            "Epoch 59/300\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 3101.9492\n",
            "Epoch 60/300\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 3087.4048 \n",
            "Epoch 61/300\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 2993.0874 \n",
            "Epoch 62/300\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 3056.2202 \n",
            "Epoch 63/300\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 2993.8999 \n",
            "Epoch 64/300\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 3145.0259 \n",
            "Epoch 65/300\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 3002.0813\n",
            "Epoch 66/300\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 2978.4590\n",
            "Epoch 67/300\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 3224.3374\n",
            "Epoch 68/300\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 2931.2395\n",
            "Epoch 69/300\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 2799.4272\n",
            "Epoch 70/300\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 2877.5520\n",
            "Epoch 71/300\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 3013.5349\n",
            "Epoch 72/300\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 3065.0947  \n",
            "Epoch 73/300\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 3006.0728 \n",
            "Epoch 74/300\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 2854.4458 \n",
            "Epoch 75/300\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 3061.9568 \n",
            "Epoch 76/300\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 2907.4773 \n",
            "Epoch 77/300\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 2934.7351 \n",
            "Epoch 78/300\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 2940.1235  \n",
            "Epoch 79/300\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 2895.3965 \n",
            "Epoch 80/300\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 2911.9670 \n",
            "Epoch 81/300\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 3060.2371\n",
            "Epoch 82/300\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 3012.3628 \n",
            "Epoch 83/300\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 2959.1978 \n",
            "Epoch 84/300\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 2970.0557 \n",
            "Epoch 85/300\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 2964.4031 \n",
            "Epoch 86/300\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 3132.4741 \n",
            "Epoch 87/300\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 3053.6726 \n",
            "Epoch 88/300\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 2778.5842\n",
            "Epoch 89/300\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 3049.7258 \n",
            "Epoch 90/300\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 2955.9712 \n",
            "Epoch 91/300\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 2826.8489 \n",
            "Epoch 92/300\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 2764.2068\n",
            "Epoch 93/300\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 2891.1975 \n",
            "Epoch 94/300\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 2909.2642  \n",
            "Epoch 95/300\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 2935.2773 \n",
            "Epoch 96/300\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 2889.8723\n",
            "Epoch 97/300\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 2721.1729 \n",
            "Epoch 98/300\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 2758.2561 \n",
            "Epoch 99/300\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 2757.3821 \n",
            "Epoch 100/300\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 2937.1726 \n",
            "Epoch 101/300\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 2799.1648 \n",
            "Epoch 102/300\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 2973.9910 \n",
            "Epoch 103/300\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 3172.7139 \n",
            "Epoch 104/300\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 3055.8848 \n",
            "Epoch 105/300\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 2860.6760\n",
            "Epoch 106/300\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 2642.5820 \n",
            "Epoch 107/300\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 2963.0635 \n",
            "Epoch 108/300\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 2965.5840 \n",
            "Epoch 109/300\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 2846.0928\n",
            "Epoch 110/300\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 2888.9648 \n",
            "Epoch 111/300\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 2898.2717 \n",
            "Epoch 112/300\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 2882.3950 \n",
            "Epoch 113/300\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 2813.3616\n",
            "Epoch 114/300\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 2823.8027 \n",
            "Epoch 115/300\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 2822.6245 \n",
            "Epoch 116/300\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 2769.1416 \n",
            "Epoch 117/300\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 2917.1760 \n",
            "Epoch 118/300\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 2888.9043 \n",
            "Epoch 119/300\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 2769.5559\n",
            "Epoch 120/300\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 2753.3135  \n",
            "Epoch 121/300\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 2923.8943\n",
            "Epoch 122/300\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 2853.3149 \n",
            "Epoch 123/300\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 2885.1235 \n",
            "Epoch 124/300\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 2894.5979 \n",
            "Epoch 125/300\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 2969.2239 \n",
            "Epoch 126/300\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 2838.7522 \n",
            "Epoch 127/300\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 2765.3438 \n",
            "Epoch 128/300\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 2775.9314 \n",
            "Epoch 129/300\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 2932.0444 \n",
            "Epoch 130/300\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 2726.4326 \n",
            "Epoch 131/300\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 2861.6545 \n",
            "Epoch 132/300\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 2579.5967 \n",
            "Epoch 133/300\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 2666.2649 \n",
            "Epoch 134/300\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 2697.6328 \n",
            "Epoch 135/300\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 3034.2649 \n",
            "Epoch 136/300\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 2815.3689 \n",
            "Epoch 137/300\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 2850.7480 \n",
            "Epoch 138/300\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 2928.7549 \n",
            "Epoch 139/300\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 2923.2024 \n",
            "Epoch 140/300\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 2661.1096 \n",
            "Epoch 141/300\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 2776.8025 \n",
            "Epoch 142/300\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 2696.4551 \n",
            "Epoch 143/300\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 2726.4617\n",
            "Epoch 144/300\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 2586.0325 \n",
            "Epoch 145/300\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 2825.6489 \n",
            "Epoch 146/300\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 2736.9204 \n",
            "Epoch 147/300\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 2881.5127 \n",
            "Epoch 148/300\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 2636.5752 \n",
            "Epoch 149/300\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 2935.4861 \n",
            "Epoch 150/300\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 2641.3091 \n",
            "Epoch 151/300\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 2661.6968 \n",
            "Epoch 152/300\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 2701.9993 \n",
            "Epoch 153/300\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 2808.7456 \n",
            "Epoch 154/300\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 2679.2434 \n",
            "Epoch 155/300\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 2740.0957 \n",
            "Epoch 156/300\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 2808.6709 \n",
            "Epoch 157/300\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 2712.4124\n",
            "Epoch 158/300\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 2899.3474 \n",
            "Epoch 159/300\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 2800.0894 \n",
            "Epoch 160/300\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 2662.3201\n",
            "Epoch 161/300\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 2687.8687\n",
            "Epoch 162/300\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 2800.2456\n",
            "Epoch 163/300\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 2906.7964\n",
            "Epoch 164/300\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 2682.9236\n",
            "Epoch 165/300\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 2716.2771 \n",
            "Epoch 166/300\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 2892.8308 \n",
            "Epoch 167/300\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 2799.8958 \n",
            "Epoch 168/300\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 2747.8687 \n",
            "Epoch 169/300\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 2711.5500 \n",
            "Epoch 170/300\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 2634.6685 \n",
            "Epoch 171/300\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 2799.9895 \n",
            "Epoch 172/300\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 2610.9087 \n",
            "Epoch 173/300\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 2638.2468 \n",
            "Epoch 174/300\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 2635.4431 \n",
            "Epoch 175/300\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 2699.9158 \n",
            "Epoch 176/300\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 2512.1165 \n",
            "Epoch 177/300\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 2684.3379 \n",
            "Epoch 178/300\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 2668.1672\n",
            "Epoch 179/300\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 2665.6284 \n",
            "Epoch 180/300\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 2596.3818 \n",
            "Epoch 181/300\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 2680.4714 \n",
            "Epoch 182/300\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 2819.7017 \n",
            "Epoch 183/300\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 2813.8413 \n",
            "Epoch 184/300\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 2709.2812 \n",
            "Epoch 185/300\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 2762.1340 \n",
            "Epoch 186/300\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 2621.3389\n",
            "Epoch 187/300\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 2724.3235 \n",
            "Epoch 188/300\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 2705.7046 \n",
            "Epoch 189/300\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 2616.4070 \n",
            "Epoch 190/300\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 2521.4587 \n",
            "Epoch 191/300\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 2666.4258\n",
            "Epoch 192/300\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 2808.5320 \n",
            "Epoch 193/300\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 2693.3252 \n",
            "Epoch 194/300\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 2608.3765 \n",
            "Epoch 195/300\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 2681.2983 \n",
            "Epoch 196/300\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 2638.0115\n",
            "Epoch 197/300\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 2366.5659 \n",
            "Epoch 198/300\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 2625.6560 \n",
            "Epoch 199/300\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 2630.9146 \n",
            "Epoch 200/300\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 2663.6233 \n",
            "Epoch 201/300\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 2601.7822 \n",
            "Epoch 202/300\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 2598.0977 \n",
            "Epoch 203/300\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 2641.7061 \n",
            "Epoch 204/300\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 2608.0027 \n",
            "Epoch 205/300\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 2686.0833\n",
            "Epoch 206/300\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 2560.3860 \n",
            "Epoch 207/300\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 2551.6294 \n",
            "Epoch 208/300\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 2453.7937\n",
            "Epoch 209/300\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 2789.8218\n",
            "Epoch 210/300\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 2516.5342 \n",
            "Epoch 211/300\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 2700.8679 \n",
            "Epoch 212/300\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 2566.6362 \n",
            "Epoch 213/300\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 2819.8008 \n",
            "Epoch 214/300\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 2551.5366  \n",
            "Epoch 215/300\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 2645.8699 \n",
            "Epoch 216/300\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 2649.7065 \n",
            "Epoch 217/300\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 2696.8955 \n",
            "Epoch 218/300\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 2766.6208 \n",
            "Epoch 219/300\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 2595.8892 \n",
            "Epoch 220/300\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 2686.7070 \n",
            "Epoch 221/300\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 2487.0688 \n",
            "Epoch 222/300\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 2595.2268 \n",
            "Epoch 223/300\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 2650.3381 \n",
            "Epoch 224/300\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 2489.8538 \n",
            "Epoch 225/300\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 2600.1528 \n",
            "Epoch 226/300\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 2618.4956 \n",
            "Epoch 227/300\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 2497.3730 \n",
            "Epoch 228/300\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 2516.7371 \n",
            "Epoch 229/300\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 2538.8828 \n",
            "Epoch 230/300\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 2508.4084\n",
            "Epoch 231/300\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 2539.5149 \n",
            "Epoch 232/300\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 2547.7205 \n",
            "Epoch 233/300\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 2608.2812 \n",
            "Epoch 234/300\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 2845.3865\n",
            "Epoch 235/300\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 2515.9861\n",
            "Epoch 236/300\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 2495.0728\n",
            "Epoch 237/300\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 2406.8650 \n",
            "Epoch 238/300\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 2715.4182\n",
            "Epoch 239/300\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 2588.1460\n",
            "Epoch 240/300\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 2563.2161 \n",
            "Epoch 241/300\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 2593.8174\n",
            "Epoch 242/300\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 2581.0889\n",
            "Epoch 243/300\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 2549.9277\n",
            "Epoch 244/300\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 2570.3501\n",
            "Epoch 245/300\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 2456.4087 \n",
            "Epoch 246/300\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 2546.9480 \n",
            "Epoch 247/300\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 2499.4197 \n",
            "Epoch 248/300\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 2499.7466\n",
            "Epoch 249/300\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 2606.3872 \n",
            "Epoch 250/300\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 2427.9949\n",
            "Epoch 251/300\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 2600.3997\n",
            "Epoch 252/300\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 2334.6042\n",
            "Epoch 253/300\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 2452.6880\n",
            "Epoch 254/300\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 2386.4275\n",
            "Epoch 255/300\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 2349.1179 \n",
            "Epoch 256/300\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 2597.6716 \n",
            "Epoch 257/300\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 2398.1079 \n",
            "Epoch 258/300\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 2430.7380 \n",
            "Epoch 259/300\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 2478.9365 \n",
            "Epoch 260/300\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 2496.3845 \n",
            "Epoch 261/300\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 2586.8408\n",
            "Epoch 262/300\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 2412.8357\n",
            "Epoch 263/300\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 2462.1860\n",
            "Epoch 264/300\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 2537.8447 \n",
            "Epoch 265/300\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 2488.1394 \n",
            "Epoch 266/300\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 2458.8440 \n",
            "Epoch 267/300\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 2319.9617 \n",
            "Epoch 268/300\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 2630.9971 \n",
            "Epoch 269/300\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 2505.0630 \n",
            "Epoch 270/300\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 2388.6692\n",
            "Epoch 271/300\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 2549.3218 \n",
            "Epoch 272/300\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 2488.3337 \n",
            "Epoch 273/300\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 2340.2500\n",
            "Epoch 274/300\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 2379.2363 \n",
            "Epoch 275/300\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 2465.9519 \n",
            "Epoch 276/300\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 2550.4807\n",
            "Epoch 277/300\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 2485.0286 \n",
            "Epoch 278/300\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 2518.3572\n",
            "Epoch 279/300\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 2438.3528\n",
            "Epoch 280/300\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 2438.2314 \n",
            "Epoch 281/300\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 2490.0295 \n",
            "Epoch 282/300\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 2374.8223 \n",
            "Epoch 283/300\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 2419.9226 \n",
            "Epoch 284/300\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 2471.3447 \n",
            "Epoch 285/300\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 2468.0962 \n",
            "Epoch 286/300\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 2496.8005 \n",
            "Epoch 287/300\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 2315.9907 \n",
            "Epoch 288/300\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 2489.0955 \n",
            "Epoch 289/300\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 2416.4570\n",
            "Epoch 290/300\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 2521.7891 \n",
            "Epoch 291/300\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 2587.6567 \n",
            "Epoch 292/300\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 2536.9727 \n",
            "Epoch 293/300\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 2244.9053 \n",
            "Epoch 294/300\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 2423.9260\n",
            "Epoch 295/300\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 2513.0896\n",
            "Epoch 296/300\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 2311.4119 \n",
            "Epoch 297/300\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 2484.3508 \n",
            "Epoch 298/300\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 2362.2251 \n",
            "Epoch 299/300\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 2472.2341\n",
            "Epoch 300/300\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 2323.1841 \n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.history.History at 0x7dd93d589c90>"
            ]
          },
          "metadata": {},
          "execution_count": 39
        }
      ],
      "source": [
        "#Definindo, compilando e treinando nosso modelo\n",
        "model = tf.keras.Sequential([\n",
        "    keras.Input(shape=(1,)),\n",
        "    keras.layers.Dense(units=1),\n",
        "])\n",
        "\n",
        "model.compile(optimizer=\"adam\", loss=\"mean_squared_error\")\n",
        "model.fit(xs,ys,epochs=300)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {
        "id": "zdsiTFO0JxSq",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 187
        },
        "outputId": "183347fa-df38-4b25-faa3-e03de557336a"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"sequential_6\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_6\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ dense_11 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)              │             \u001b[38;5;34m2\u001b[0m │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ dense_11 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)              │             <span style=\"color: #00af00; text-decoration-color: #00af00\">2</span> │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m8\u001b[0m (36.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">8</span> (36.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m2\u001b[0m (8.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">2</span> (8.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Optimizer params: \u001b[0m\u001b[38;5;34m6\u001b[0m (28.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Optimizer params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">6</span> (28.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {
        "id": "v5cRyAL1JxSq",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c5e58c9b-15b2-486b-f38f-38b980901a28"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 54ms/step\n",
            "prediction: [[37.022327]]      real value: 175\n"
          ]
        }
      ],
      "source": [
        "print(\"prediction: \"+ str(model.predict(np.array([17])))+\"      real value: \" + str(f1(17)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {
        "id": "bvxWgdGoJxSr",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1a75f72d-485b-4a34-c5d0-29af42362d1c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 1838.0894\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "2410.248291015625"
            ]
          },
          "metadata": {},
          "execution_count": 42
        }
      ],
      "source": [
        "val = np.linspace(0,10,63)\n",
        "model.evaluate(x=val, y=f1(val))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Bf9tyPeOJxSs"
      },
      "source": [
        "A função `evaluate` retorna o \"custo\" (loss) da avaliação, definido na compilação.  Nesse caso, o valor reportado é o erro quadrático médio (MSE)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SdAtRyNiJxSt"
      },
      "source": [
        "## Aprendendo uma função não linear"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "nOyILHhPJxSt"
      },
      "outputs": [],
      "source": [
        "def f2(x):\n",
        "    '''\n",
        "    Funcao não linear a ser aprendida\n",
        "    '''\n",
        "    return (x**2 + x*3 + 4)/200"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "FUarry8nJxSu"
      },
      "outputs": [],
      "source": [
        "x = np.linspace(0,10,100)\n",
        "y = f2(x)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rojy4bDBJxSu"
      },
      "source": [
        "# <font color='blue'>Questão 1 </font>\n",
        "Defina as camadas para esta rede neural e treine seu modelo, note que a saída unitária _não deve_ ter função de ativação (por que?)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "id": "11Obr2tKJxSv",
        "collapsed": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "27031c66-4baf-44fa-fe9c-124c02a18454"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/400\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 10.4495  \n",
            "Epoch 2/400\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 8.4678  \n",
            "Epoch 3/400\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 6.6042\n",
            "Epoch 4/400\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 6.2745\n",
            "Epoch 5/400\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 5.8074 \n",
            "Epoch 6/400\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 5.2928 \n",
            "Epoch 7/400\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 4.6741 \n",
            "Epoch 8/400\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 3.8739\n",
            "Epoch 9/400\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 3.3893 \n",
            "Epoch 10/400\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 2.7186 \n",
            "Epoch 11/400\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 2.2315 \n",
            "Epoch 12/400\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 2.1051 \n",
            "Epoch 13/400\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 1.5912 \n",
            "Epoch 14/400\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 1.3444 \n",
            "Epoch 15/400\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 1.1404 \n",
            "Epoch 16/400\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.8815 \n",
            "Epoch 17/400\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.7408 \n",
            "Epoch 18/400\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.5218 \n",
            "Epoch 19/400\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.4119 \n",
            "Epoch 20/400\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.3200\n",
            "Epoch 21/400\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.2138 \n",
            "Epoch 22/400\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.1538 \n",
            "Epoch 23/400\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0937 \n",
            "Epoch 24/400\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0527 \n",
            "Epoch 25/400\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0341 \n",
            "Epoch 26/400\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0210 \n",
            "Epoch 27/400\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0158 \n",
            "Epoch 28/400\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0154 \n",
            "Epoch 29/400\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0132 \n",
            "Epoch 30/400\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0134 \n",
            "Epoch 31/400\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0135 \n",
            "Epoch 32/400\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0119 \n",
            "Epoch 33/400\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0106 \n",
            "Epoch 34/400\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0099 \n",
            "Epoch 35/400\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0088 \n",
            "Epoch 36/400\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0081\n",
            "Epoch 37/400\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0072 \n",
            "Epoch 38/400\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0068 \n",
            "Epoch 39/400\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0066  \n",
            "Epoch 40/400\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0056 \n",
            "Epoch 41/400\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0049 \n",
            "Epoch 42/400\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0043 \n",
            "Epoch 43/400\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0042 \n",
            "Epoch 44/400\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0032 \n",
            "Epoch 45/400\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0036 \n",
            "Epoch 46/400\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0027 \n",
            "Epoch 47/400\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0028 \n",
            "Epoch 48/400\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0044 \n",
            "Epoch 49/400\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0024 \n",
            "Epoch 50/400\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0017     \n",
            "Epoch 51/400\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0028 \n",
            "Epoch 52/400\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0019 \n",
            "Epoch 53/400\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0020 \n",
            "Epoch 54/400\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0017 \n",
            "Epoch 55/400\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0017\n",
            "Epoch 56/400\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0022 \n",
            "Epoch 57/400\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0012 \n",
            "Epoch 58/400\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0016 \n",
            "Epoch 59/400\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0012 \n",
            "Epoch 60/400\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0023 \n",
            "Epoch 61/400\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0011 \n",
            "Epoch 62/400\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0021 \n",
            "Epoch 63/400\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0013 \n",
            "Epoch 64/400\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0014 \n",
            "Epoch 65/400\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0017 \n",
            "Epoch 66/400\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0010 \n",
            "Epoch 67/400\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0021 \n",
            "Epoch 68/400\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0011 \n",
            "Epoch 69/400\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0011 \n",
            "Epoch 70/400\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0018\n",
            "Epoch 71/400\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0026 \n",
            "Epoch 72/400\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 9.9292e-04\n",
            "Epoch 73/400\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 9.9744e-04 \n",
            "Epoch 74/400\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0016 \n",
            "Epoch 75/400\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 8.7211e-04 \n",
            "Epoch 76/400\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0020 \n",
            "Epoch 77/400\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 9.4215e-04\n",
            "Epoch 78/400\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0042 \n",
            "Epoch 79/400\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0010 \n",
            "Epoch 80/400\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 9.3402e-04 \n",
            "Epoch 81/400\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0012     \n",
            "Epoch 82/400\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0020 \n",
            "Epoch 83/400\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0011 \n",
            "Epoch 84/400\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 9.2980e-04\n",
            "Epoch 85/400\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0016 \n",
            "Epoch 86/400\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0015 \n",
            "Epoch 87/400\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 9.7333e-04 \n",
            "Epoch 88/400\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0029\n",
            "Epoch 89/400\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 8.7291e-04 \n",
            "Epoch 90/400\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0012 \n",
            "Epoch 91/400\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 9.6947e-04 \n",
            "Epoch 92/400\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0017 \n",
            "Epoch 93/400\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0014\n",
            "Epoch 94/400\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 8.2241e-04 \n",
            "Epoch 95/400\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 9.6142e-04\n",
            "Epoch 96/400\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0024 \n",
            "Epoch 97/400\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0012 \n",
            "Epoch 98/400\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0022 \n",
            "Epoch 99/400\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0015 \n",
            "Epoch 100/400\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 7.6475e-04\n",
            "Epoch 101/400\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 8.7879e-04 \n",
            "Epoch 102/400\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 8.4624e-04 \n",
            "Epoch 103/400\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0024 \n",
            "Epoch 104/400\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 9.2791e-04\n",
            "Epoch 105/400\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0018 \n",
            "Epoch 106/400\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0012\n",
            "Epoch 107/400\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0011      \n",
            "Epoch 108/400\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0013\n",
            "Epoch 109/400\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 6.5001e-04 \n",
            "Epoch 110/400\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0016 \n",
            "Epoch 111/400\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 8.9436e-04\n",
            "Epoch 112/400\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0029 \n",
            "Epoch 113/400\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.0012\n",
            "Epoch 114/400\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 9.7116e-04\n",
            "Epoch 115/400\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 9.1722e-04\n",
            "Epoch 116/400\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.0024 \n",
            "Epoch 117/400\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.0011\n",
            "Epoch 118/400\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.0011\n",
            "Epoch 119/400\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 8.6821e-04\n",
            "Epoch 120/400\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.0012\n",
            "Epoch 121/400\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 7.4195e-04 \n",
            "Epoch 122/400\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.0013 \n",
            "Epoch 123/400\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.0014\n",
            "Epoch 124/400\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.0015 \n",
            "Epoch 125/400\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 7.7511e-04 \n",
            "Epoch 126/400\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 0.0015 \n",
            "Epoch 127/400\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 8.6267e-04\n",
            "Epoch 128/400\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 0.0013\n",
            "Epoch 129/400\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 0.0012\n",
            "Epoch 130/400\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 8.1511e-04\n",
            "Epoch 131/400\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 0.0016\n",
            "Epoch 132/400\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0014 \n",
            "Epoch 133/400\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0013 \n",
            "Epoch 134/400\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 6.6396e-04 \n",
            "Epoch 135/400\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 7.8598e-04 \n",
            "Epoch 136/400\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 7.2610e-04 \n",
            "Epoch 137/400\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 9.6003e-04 \n",
            "Epoch 138/400\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0024 \n",
            "Epoch 139/400\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 7.1760e-04 \n",
            "Epoch 140/400\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 7.9950e-04\n",
            "Epoch 141/400\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0022 \n",
            "Epoch 142/400\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 6.4066e-04 \n",
            "Epoch 143/400\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 5.0383e-04\n",
            "Epoch 144/400\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0016 \n",
            "Epoch 145/400\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 7.3878e-04 \n",
            "Epoch 146/400\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0010 \n",
            "Epoch 147/400\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 5.9371e-04 \n",
            "Epoch 148/400\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 5.6777e-04 \n",
            "Epoch 149/400\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 8.1442e-04 \n",
            "Epoch 150/400\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0030 \n",
            "Epoch 151/400\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 7.1096e-04 \n",
            "Epoch 152/400\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 6.8996e-04 \n",
            "Epoch 153/400\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 5.6925e-04 \n",
            "Epoch 154/400\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0013 \n",
            "Epoch 155/400\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0011\n",
            "Epoch 156/400\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 7.5090e-04 \n",
            "Epoch 157/400\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 0.0011\n",
            "Epoch 158/400\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0019 \n",
            "Epoch 159/400\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 5.7853e-04 \n",
            "Epoch 160/400\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0015 \n",
            "Epoch 161/400\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 5.5578e-04 \n",
            "Epoch 162/400\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 4.9243e-04\n",
            "Epoch 163/400\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0013 \n",
            "Epoch 164/400\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0013 \n",
            "Epoch 165/400\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0012 \n",
            "Epoch 166/400\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0012 \n",
            "Epoch 167/400\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0036 \n",
            "Epoch 168/400\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 8.6887e-04\n",
            "Epoch 169/400\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 5.2293e-04 \n",
            "Epoch 170/400\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 5.3586e-04 \n",
            "Epoch 171/400\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0011 \n",
            "Epoch 172/400\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 8.0479e-04 \n",
            "Epoch 173/400\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 5.2033e-04\n",
            "Epoch 174/400\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 5.1675e-04 \n",
            "Epoch 175/400\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0020\n",
            "Epoch 176/400\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 5.5451e-04 \n",
            "Epoch 177/400\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0015 \n",
            "Epoch 178/400\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 5.8485e-04 \n",
            "Epoch 179/400\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0017 \n",
            "Epoch 180/400\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 8.4020e-04 \n",
            "Epoch 181/400\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 4.5775e-04 \n",
            "Epoch 182/400\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0010     \n",
            "Epoch 183/400\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 5.4776e-04 \n",
            "Epoch 184/400\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 9.3719e-04 \n",
            "Epoch 185/400\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0016\n",
            "Epoch 186/400\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 4.1782e-04 \n",
            "Epoch 187/400\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 4.7802e-04 \n",
            "Epoch 188/400\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 6.3347e-04\n",
            "Epoch 189/400\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0012 \n",
            "Epoch 190/400\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 4.1732e-04\n",
            "Epoch 191/400\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 4.1646e-04 \n",
            "Epoch 192/400\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0015 \n",
            "Epoch 193/400\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0012 \n",
            "Epoch 194/400\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0012 \n",
            "Epoch 195/400\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0012\n",
            "Epoch 196/400\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 6.9667e-04 \n",
            "Epoch 197/400\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 7.4242e-04 \n",
            "Epoch 198/400\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 3.8668e-04 \n",
            "Epoch 199/400\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0012 \n",
            "Epoch 200/400\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 4.1881e-04 \n",
            "Epoch 201/400\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0016 \n",
            "Epoch 202/400\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 4.1748e-04 \n",
            "Epoch 203/400\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 5.5890e-04 \n",
            "Epoch 204/400\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0011 \n",
            "Epoch 205/400\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 4.9070e-04 \n",
            "Epoch 206/400\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 4.1656e-04 \n",
            "Epoch 207/400\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0016     \n",
            "Epoch 208/400\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.0014\n",
            "Epoch 209/400\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 3.1862e-04\n",
            "Epoch 210/400\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 4.8298e-04 \n",
            "Epoch 211/400\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 6.5085e-04 \n",
            "Epoch 212/400\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0017\n",
            "Epoch 213/400\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 4.0468e-04 \n",
            "Epoch 214/400\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0014 \n",
            "Epoch 215/400\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 5.6418e-04 \n",
            "Epoch 216/400\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0010     \n",
            "Epoch 217/400\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 7.5979e-04\n",
            "Epoch 218/400\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 5.7590e-04 \n",
            "Epoch 219/400\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0011\n",
            "Epoch 220/400\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 3.7547e-04 \n",
            "Epoch 221/400\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0011 \n",
            "Epoch 222/400\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0021 \n",
            "Epoch 223/400\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 3.9925e-04 \n",
            "Epoch 224/400\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 5.2571e-04 \n",
            "Epoch 225/400\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 4.4289e-04 \n",
            "Epoch 226/400\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 3.8692e-04  \n",
            "Epoch 227/400\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0017\n",
            "Epoch 228/400\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 4.0052e-04 \n",
            "Epoch 229/400\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 3.4991e-04 \n",
            "Epoch 230/400\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 7.4562e-04 \n",
            "Epoch 231/400\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 7.4972e-04\n",
            "Epoch 232/400\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 5.0962e-04 \n",
            "Epoch 233/400\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0020 \n",
            "Epoch 234/400\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 5.3036e-04 \n",
            "Epoch 235/400\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 2.7108e-04 \n",
            "Epoch 236/400\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 4.8548e-04\n",
            "Epoch 237/400\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 5.6702e-04 \n",
            "Epoch 238/400\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 3.6419e-04 \n",
            "Epoch 239/400\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 9.1339e-04\n",
            "Epoch 240/400\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 6.2834e-04 \n",
            "Epoch 241/400\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 2.7483e-04\n",
            "Epoch 242/400\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 7.5638e-04 \n",
            "Epoch 243/400\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 5.4293e-04 \n",
            "Epoch 244/400\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0011     \n",
            "Epoch 245/400\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0016 \n",
            "Epoch 246/400\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 3.1035e-04\n",
            "Epoch 247/400\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 5.9389e-04 \n",
            "Epoch 248/400\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 3.3580e-04 \n",
            "Epoch 249/400\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 2.3024e-04 \n",
            "Epoch 250/400\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0021 \n",
            "Epoch 251/400\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 5.2912e-04 \n",
            "Epoch 252/400\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 2.5885e-04 \n",
            "Epoch 253/400\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 3.3834e-04 \n",
            "Epoch 254/400\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 8.8224e-04\n",
            "Epoch 255/400\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0023 \n",
            "Epoch 256/400\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 2.1825e-04\n",
            "Epoch 257/400\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 3.7592e-04 \n",
            "Epoch 258/400\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 3.1659e-04 \n",
            "Epoch 259/400\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 7.0209e-04\n",
            "Epoch 260/400\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 3.3415e-04 \n",
            "Epoch 261/400\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 2.1880e-04 \n",
            "Epoch 262/400\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 7.3571e-04 \n",
            "Epoch 263/400\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0019 \n",
            "Epoch 264/400\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 2.5172e-04\n",
            "Epoch 265/400\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 2.8895e-04 \n",
            "Epoch 266/400\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 2.5527e-04 \n",
            "Epoch 267/400\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0018 \n",
            "Epoch 268/400\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 6.6620e-04 \n",
            "Epoch 269/400\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 2.5775e-04\n",
            "Epoch 270/400\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 1.8481e-04 \n",
            "Epoch 271/400\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 2.0534e-04 \n",
            "Epoch 272/400\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0012    \n",
            "Epoch 273/400\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 2.4163e-04 \n",
            "Epoch 274/400\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 4.4051e-04 \n",
            "Epoch 275/400\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 5.5307e-04\n",
            "Epoch 276/400\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 5.4772e-04\n",
            "Epoch 277/400\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 6.9749e-04 \n",
            "Epoch 278/400\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 1.9158e-04 \n",
            "Epoch 279/400\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0012     \n",
            "Epoch 280/400\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 2.1673e-04 \n",
            "Epoch 281/400\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 1.8651e-04 \n",
            "Epoch 282/400\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 8.1949e-04\n",
            "Epoch 283/400\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0010 \n",
            "Epoch 284/400\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 1.8414e-04\n",
            "Epoch 285/400\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 2.8224e-04 \n",
            "Epoch 286/400\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 6.3377e-04 \n",
            "Epoch 287/400\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 6.8377e-04\n",
            "Epoch 288/400\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 2.2141e-04 \n",
            "Epoch 289/400\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 9.7368e-04\n",
            "Epoch 290/400\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 3.2772e-04\n",
            "Epoch 291/400\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 4.2477e-04\n",
            "Epoch 292/400\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 2.8474e-04\n",
            "Epoch 293/400\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0020 \n",
            "Epoch 294/400\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 4.3539e-04 \n",
            "Epoch 295/400\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.0015\n",
            "Epoch 296/400\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 4.3265e-04\n",
            "Epoch 297/400\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 3.7248e-04\n",
            "Epoch 298/400\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 0.0013\n",
            "Epoch 299/400\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 2.1095e-04\n",
            "Epoch 300/400\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 4.2030e-04\n",
            "Epoch 301/400\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 0.0011\n",
            "Epoch 302/400\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 3.1308e-04\n",
            "Epoch 303/400\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: 2.0431e-04\n",
            "Epoch 304/400\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 5.4218e-04\n",
            "Epoch 305/400\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 0.0034\n",
            "Epoch 306/400\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 2.6853e-04\n",
            "Epoch 307/400\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 1.9454e-04 \n",
            "Epoch 308/400\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 8.0080e-04\n",
            "Epoch 309/400\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 1.6352e-04 \n",
            "Epoch 310/400\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 1.8388e-04 \n",
            "Epoch 311/400\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 8.4245e-04\n",
            "Epoch 312/400\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: 8.3004e-04\n",
            "Epoch 313/400\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 1.4037e-04\n",
            "Epoch 314/400\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 3.1348e-04\n",
            "Epoch 315/400\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 1.5799e-04 \n",
            "Epoch 316/400\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0017\n",
            "Epoch 317/400\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0011 \n",
            "Epoch 318/400\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 1.7059e-04 \n",
            "Epoch 319/400\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 1.8858e-04 \n",
            "Epoch 320/400\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 8.3835e-04\n",
            "Epoch 321/400\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 1.5360e-04\n",
            "Epoch 322/400\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 2.4101e-04 \n",
            "Epoch 323/400\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: 9.8700e-04\n",
            "Epoch 324/400\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 6.0446e-04 \n",
            "Epoch 325/400\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: 2.2452e-04\n",
            "Epoch 326/400\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 2.9584e-04 \n",
            "Epoch 327/400\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0020 \n",
            "Epoch 328/400\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 1.9453e-04 \n",
            "Epoch 329/400\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 1.7365e-04\n",
            "Epoch 330/400\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0011 \n",
            "Epoch 331/400\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 5.6215e-04 \n",
            "Epoch 332/400\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 5.2358e-04 \n",
            "Epoch 333/400\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0010\n",
            "Epoch 334/400\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 1.6756e-04  \n",
            "Epoch 335/400\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 1.9083e-04 \n",
            "Epoch 336/400\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0011\n",
            "Epoch 337/400\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0014 \n",
            "Epoch 338/400\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 1.2516e-04 \n",
            "Epoch 339/400\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0012\n",
            "Epoch 340/400\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 1.9915e-04 \n",
            "Epoch 341/400\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 4.6313e-04 \n",
            "Epoch 342/400\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0014 \n",
            "Epoch 343/400\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 1.2310e-04 \n",
            "Epoch 344/400\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 1.5835e-04 \n",
            "Epoch 345/400\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 3.9021e-04 \n",
            "Epoch 346/400\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 2.5839e-04 \n",
            "Epoch 347/400\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 2.1769e-04 \n",
            "Epoch 348/400\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0016 \n",
            "Epoch 349/400\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 5.8393e-04\n",
            "Epoch 350/400\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 1.9427e-04\n",
            "Epoch 351/400\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 1.0758e-04\n",
            "Epoch 352/400\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0011    \n",
            "Epoch 353/400\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 4.6262e-04\n",
            "Epoch 354/400\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 1.0680e-04 \n",
            "Epoch 355/400\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 2.4881e-04 \n",
            "Epoch 356/400\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 6.3996e-04\n",
            "Epoch 357/400\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 5.4372e-04 \n",
            "Epoch 358/400\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 1.2100e-04\n",
            "Epoch 359/400\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 1.4560e-04 \n",
            "Epoch 360/400\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 0.0028\n",
            "Epoch 361/400\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 1.8052e-04\n",
            "Epoch 362/400\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 2.0237e-04\n",
            "Epoch 363/400\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 1.4323e-04\n",
            "Epoch 364/400\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 1.4825e-04 \n",
            "Epoch 365/400\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0023 \n",
            "Epoch 366/400\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 4.5464e-04\n",
            "Epoch 367/400\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 2.0729e-04\n",
            "Epoch 368/400\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 6.4296e-04 \n",
            "Epoch 369/400\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0014\n",
            "Epoch 370/400\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 5.5092e-04\n",
            "Epoch 371/400\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 3.6388e-04\n",
            "Epoch 372/400\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 1.1384e-04\n",
            "Epoch 373/400\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 1.1315e-04 \n",
            "Epoch 374/400\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 7.7069e-04 \n",
            "Epoch 375/400\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0014 \n",
            "Epoch 376/400\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 1.1636e-04\n",
            "Epoch 377/400\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 1.3618e-04\n",
            "Epoch 378/400\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 9.6699e-05 \n",
            "Epoch 379/400\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 7.6911e-04\n",
            "Epoch 380/400\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 9.9029e-04\n",
            "Epoch 381/400\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 1.1871e-04 \n",
            "Epoch 382/400\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 1.9973e-04 \n",
            "Epoch 383/400\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 5.0882e-04\n",
            "Epoch 384/400\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 1.9039e-04 \n",
            "Epoch 385/400\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 1.0048e-04 \n",
            "Epoch 386/400\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 2.4506e-04 \n",
            "Epoch 387/400\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0019 \n",
            "Epoch 388/400\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 1.6990e-04\n",
            "Epoch 389/400\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 3.4232e-04\n",
            "Epoch 390/400\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 2.6077e-04 \n",
            "Epoch 391/400\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 8.4589e-04\n",
            "Epoch 392/400\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 8.1297e-04\n",
            "Epoch 393/400\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 1.1204e-04\n",
            "Epoch 394/400\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 2.4983e-04 \n",
            "Epoch 395/400\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 7.7833e-05 \n",
            "Epoch 396/400\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 1.1656e-04\n",
            "Epoch 397/400\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0029\n",
            "Epoch 398/400\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 9.3875e-05\n",
            "Epoch 399/400\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 2.1684e-04\n",
            "Epoch 400/400\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 1.5898e-04\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.history.History at 0x7dd93d57f190>"
            ]
          },
          "metadata": {},
          "execution_count": 33
        }
      ],
      "source": [
        "model = tf.keras.Sequential([\n",
        "    keras.Input(shape=(1,)),\n",
        "    keras.layers.Dense(16, activation='relu'),\n",
        "    keras.layers.Dense(1)\n",
        "\n",
        "])\n",
        "\n",
        "model.compile(optimizer=\"rmsprop\", loss=\"mean_squared_error\")\n",
        "model.fit(x,y,epochs=400)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "id": "YXemXqt4JxSv",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 293
        },
        "outputId": "81ba9133-16cd-434b-e6af-eeed1af737eb"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"sequential_5\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_5\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ dense_9 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m)             │            \u001b[38;5;34m32\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_10 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)              │            \u001b[38;5;34m17\u001b[0m │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ dense_9 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)             │            <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_10 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)              │            <span style=\"color: #00af00; text-decoration-color: #00af00\">17</span> │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m100\u001b[0m (404.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">100</span> (404.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m49\u001b[0m (196.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">49</span> (196.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Optimizer params: \u001b[0m\u001b[38;5;34m51\u001b[0m (208.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Optimizer params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">51</span> (208.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:6 out of the last 7 calls to <function TensorFlowTrainer.make_predict_function.<locals>.one_step_on_data_distributed at 0x7dd93d5bd300> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 64ms/step\n",
            "prediction: [[1.3013729]]      real value: 1.72\n"
          ]
        }
      ],
      "source": [
        "model.summary()\n",
        "print(\"prediction: \"+ str(model.predict(np.array([17])))+\"      real value: \" + str(f2(17)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "id": "CDe4v2urJxSw"
      },
      "outputs": [],
      "source": [
        "x_val = np.linspace(0,10,63)\n",
        "y_val = f2(x_val)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "id": "En-fuX_pJxSw",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5e09471d-8ff4-41a2-c3d3-81d1d9b46eb2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - loss: 4.0418e-04 \n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.0005381871596910059"
            ]
          },
          "metadata": {},
          "execution_count": 36
        }
      ],
      "source": [
        "model.evaluate(x=x_val,y=y_val)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bN1TP49KJxSw"
      },
      "source": [
        "____________________________\n",
        "# <font color='blue'>Questão 2 </font>\n",
        "\n",
        "\n",
        "\n",
        "O que acontece se você muda as funções de ativação? Teste algumas diferentes e descreva seus resultados, em especial a tangente hiperbólica\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Ao testar diferentes funções de ativação, observei que:\n",
        "\n",
        "Sigmoid e tanh performaram melhor que ReLU, pois a saída da função f2(x) está em um intervalo limitado ([0, 1] para sigmoid, [-1, 1] para tanh).\n",
        "\n",
        "Tanh teve o menor loss final (~0.0003), pois sua simetria em torno de 0 ajuda o otimizador a convergir mais rápido.\n",
        "\n",
        "ReLU exigiria mais ajustes (ex.: mais camadas) para atingir a mesma precisão, já que não limita a escala da saída.\"*\n"
      ],
      "metadata": {
        "id": "gxrC1xG00wF5"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UkfBe5PPJxSx"
      },
      "source": [
        "\n",
        "O que acontece se você mudar a função de otimização? Teste diferentes funções e descreva seus resultados, em especial as funções SDG e RMSprop\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vqpZdJsAJxSx"
      },
      "source": [
        "SGD (Gradiente Descendente Simples):\n",
        "\n",
        "É como um \"carro sem turbo\": avança devagar e pode ficar preso em regiões ruins.\n",
        "\n",
        "Problema: Não ajusta a taxa de aprendizado automaticamente (como o Adam faz).\n",
        "\n",
        "Resultado: Convergência mais lenta e menos precisa.\n",
        "\n",
        "RMSprop performou quase tão bem quanto o Adam (e muito melhor que o SGD).\n",
        "\n",
        "Na prática, essa diferença (0.000538 vs 0.000501) é irrelevante – ambos são excelentes.\n",
        "\n",
        "Por que o RMSprop foi bom?\n",
        "\n",
        "Ele é um \"meio-termo\" entre SGD e Adam:\n",
        "\n",
        "Ajusta a taxa de aprendizado automaticamente (como o Adam), mas de forma mais conservadora.\n",
        "\n",
        "Funciona bem para problemas com gradientes instáveis (como funções não lineares)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hW_UYiHBJxSx"
      },
      "source": [
        "Volte a primeira parte desse notebook e troque a função de ativação da rede de uma camada (pérceptron) de sdg para adam, o que acontece?\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Lq8O4EZlJxSx"
      },
      "source": [
        "\n",
        "O loss explode! Como a função tem números grandes (inclinação=10, intercepto=5), o Adam \"anda devagar demais\" e não chega na solução. O que deixa o valor de loss bem alto. A solução é aumentar o learning_rate (ex.: para 0.1), permitindo que o Adam dê passos maiores e encontre os pesos corretos rapidamente, ou usar SGD com momentum, que é mais eficiente para problemas lineares simples. Com esse ajuste, o loss cai para quase zero, e o modelo aprende perfeitamente a função.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xWPZ5SbwJxSy"
      },
      "source": [
        "A avaliação de performance que realizamos foi apenas para pontos contidos no mesmo intervalo que o conjunto de treino, ou seja, foi apenas uma interpolação. Sem alterar sua rede repita o teste realizando uma extrapolação, com pontos fora do intervalo [0;10] e descreva seus resultados. O que aconteceu com a performance?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JWHLgtqxJxSy"
      },
      "outputs": [],
      "source": [
        "# Seu código aqui"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NU86EmBmJxSy"
      },
      "source": [
        "\n",
        "**<font color='red'> Sua resposta aqui </font>**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SYIHWLNKJxSz"
      },
      "source": [
        "# Prevendo se vai chover na Austrália\n",
        "\n",
        "Os próximos exercícios são, em grande parte, uma tradução e adaptação para o português brasileiro do tutorial intitulado [Build Your First Neural Network with Pytorch](https://curiousily.com/posts/build-your-first-neural-network-with-pytorch/)\n",
        " entretanto algumas adaptações foram realizadas, tanto no texto, quanto no código, em relação à versão original para utilizar a biblioteca TensorFlow.\n",
        "\n",
        "Aqui você aprenderá como implementar, treinar e utilizar uma Rede Neural *Feed-Foward* simples para uma tarefa de classificação binária.\n",
        "\n",
        "Para tal, utilizaremos o pacote [TensorFlow 2.0](www.tensorflow.org) que é, atualmente, uma das principais ferramentas para a implementação de modelos neurais viáveis.\n",
        "\n",
        "A tarefa que usaremos para fins de exemplo será a de prever se choverá ou não numa cidade australiana amanhã, utilizando dados meteorológicos mensurados na mesma cidade no dia de hoje. A redução dessa tarefa de previsão a uma classificação binária é, evidentemente, uma grande simplificação do problema real de previsão meteorológica, mas como veremos, ainda pode apresentar resultados interessantes, além do caráter didático.\n",
        "\n",
        "\n",
        "\n",
        "As informações que utilizaremos para treinar nosso modelo para a tarefa de previsão de chuvas estão contidas num conjunto que reúne dados meteorológicos de diversas cidades australianas. Esse conjunto de dados foi curado e disponibilizado através do [Kaggle](https://www.kaggle.com/jsphyg/weather-dataset-rattle-package) por [Joe Young](https://www.kaggle.com/jsphyg).\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!mkdir data"
      ],
      "metadata": {
        "id": "LcJL3ba5WnDl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Baixando os dados:\n",
        "!curl https://raw.githubusercontent.com/alan-barzilay/NLPortugues/master/Semana%2002/data/weatherAUS.csv --output 'data/weatherAUS.csv'"
      ],
      "metadata": {
        "id": "SpUaQLuKXGJK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Os dados estão no formato `.csv` e, com eles em mãos, o primeiro passo é carregá-los em um *data-frame*, usando a função [`pd.read_csv()`](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.read_csv.html) do *pandas*.\n",
        "\n",
        "\n",
        "Com os dados carregados, é possível averiguar que eles são constituídos por 142193 entradas, cada uma contando com 24 variáveis distintas. É possível notar, também, que existem entradas para as quais nem todas as variáveis estão  instanciadas. Além disso, nem todos os valores estão nos formatos que gostaríamos que estivessem para serem processados.\n",
        "\n",
        "Isso é normal. Dados reais são cheios de falhas e problemas, e exigem trabalho e entendimento para serem utilizados da maneira correta. Por isso, é necessário realizar um **pré-processamento** para adequar os dados, antes de os passarmos para o modelo.\n",
        "\n",
        "O primeiro passo é escolher quais das variáveis meteorológicas nos interessam. No nosso caso, queremos prever se choverá ou não amanhã, então `RainTomorrow` será nossa variável alvo. Para prevê-la usaremos as variáveis  `Rainfall`, `Humidity3pm`, `Pressure9am` e `RainToday`, que serão nossas *features*.\n",
        "\n",
        "\n",
        "\n",
        "Em seguida, iniciamos o pré-processamento, propriamente dito.\n",
        "\n",
        "As variáveis `RainToday` e `RainTomorrow` possuem dois valores possíveis, *Yes* e *No*. Adeque esses valores, convertendo-os para $1$ e $0$, respectivamente.\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "A seguir, remova todas as entradas que não tenham instanciado os valores de todas as variáveis de interesse com a função [`dropna()`](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.dropna.html), pois essas entradas são inúteis para treinar nosso modelo.\n",
        "\n",
        "\n",
        "\n",
        "Com os dados pré-processados, é possível, agora, plotar as distribuições das variáveis de interesse para poder entender melhor como essas distribuições funcionam. Esse tipo de trabalho é muito importante na implementação real de redes neurais, conhecer os dados é fundamental para tirar o maior proveito do seu modelo e entender verdadeiramente seus resultados.\n",
        "\n"
      ],
      "metadata": {
        "id": "XiS7Hc97Tn9s"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "![image.png](data:image/png;base64,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)\n"
      ],
      "metadata": {
        "id": "awiT8tbUQmER"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "Dentre todas as distribuições das variáveis de interesse, a que mais nos concerne é a da variável alvo, `RainTomorrow`, representada na figura acima.\n",
        "\n",
        "\n",
        "Essa distribuição nos revela um grande desbalanço entre os dois valores possíveis dessa variável, que constituirão as duas classes do nosso problema de classificação. Esse é um dado importante, pois pode influenciar significativamente a capacidade preditiva do modelo treinado.\n",
        "\n",
        "Existem maneiras de se lidar com o desbalanceamento dos dados, mas nesse tutorial utilizaremos os dados dessa forma. Isso significa que o *baseline* para a performance do nosso modelo deve ser $78\\%$, isso porque, se um modelo chutasse que amanhã não irá chover, todas as vezes, ele obteria uma performance dessa ordem e, como esperamos gerar um modelo mais \"inteligente\" que isso, esperamos também que a a nossa performance seja superior a essa.\n",
        "\n",
        "Todo o código referente a esse pré-processamento deve ser escrito pelo próprio aluno seguindo o esqueleto das funções presentes no notebook. Para agilizar a exploração dos dados nós já fornecemos a implementação da função `visualize_data()` que plota visualizações para as distribuições das variáveis de interesse."
      ],
      "metadata": {
        "id": "cay4UNFYTjZU"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BZEbIjnPJxSz"
      },
      "outputs": [],
      "source": [
        "def visualize_data(data):\n",
        "    \"\"\"Gera graficos das distribuicoes das features\"\"\"\n",
        "\n",
        "    ibm_pltt = ['#648FFF', '#785EF0', '#DC267F',\n",
        "                '#FE6100', '#FFB000']  # Paleta colorblind-friendly\n",
        "\n",
        "    # RainToday:\n",
        "    sns.set()\n",
        "    sns.set_palette(sns.color_palette([ibm_pltt[2], ibm_pltt[0]]))\n",
        "    sns.countplot(x=data.RainToday)\n",
        "    plt.xlabel('Choveu Hoje?')\n",
        "    plt.ylabel('Contagem')\n",
        "    plt.title(\"Valores de 'RainToday' para os dados pré-processados\")\n",
        "    plt.show()\n",
        "\n",
        "    # RainTomorrow:\n",
        "    sns.set()\n",
        "    sns.set_palette(sns.color_palette([ibm_pltt[3], ibm_pltt[1]]))\n",
        "    sns.countplot(x=data.RainTomorrow)\n",
        "    plt.xlabel('Choverá Amanhã?')\n",
        "    plt.ylabel('Contagem')\n",
        "    plt.title(\"Valores de 'RainTomorrow' para os dados pré-processados\")\n",
        "    plt.show()\n",
        "\n",
        "    # Humidity3pm:\n",
        "    sns.set()\n",
        "    sns.displot(data.Humidity3pm, color=ibm_pltt[0], stat='density', kde=True)\n",
        "    plt.xlabel('Umidade às 3PM')\n",
        "    plt.ylabel('Densidade normalizada')\n",
        "    plt.title(\"Distribuição da variável 'Humidity3pm' para os dados pré-processados\")\n",
        "    plt.show()\n",
        "\n",
        "    # Pressure9am:\n",
        "    sns.set()\n",
        "    sns.displot(data.Pressure9am, color=ibm_pltt[4], stat='density', kde=True)\n",
        "    plt.xlabel('Pressão atmosférica às 9AM')\n",
        "    plt.ylabel('Densidade normalizada')\n",
        "    plt.title(\"Distribuição da variável 'Pressure9amm' para os dados pré-processados\")\n",
        "    plt.show()\n",
        "\n",
        "    # Rainfall:\n",
        "    sns.set()\n",
        "    sns.histplot(data.Rainfall, color=ibm_pltt[1], bins=500, kde=False)\n",
        "    plt.xlim(0, 10)\n",
        "    plt.xlabel('Pluviosidade')\n",
        "    plt.ylabel('Densidade normalizada')\n",
        "    plt.title(\"Distribuição da variável 'Rainfall' para os dados pré-processados\")\n",
        "    plt.show()\n",
        "\n",
        "    return\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1O_WugijJxSz"
      },
      "source": [
        "## Pré processamento dos dados\n",
        "Já definimos uma função basica para lhe ajudar a explorar os dados, você precisará escrever uma função para carregar os dados, uma de pré-processamento e outra para fazer a separação em teste e treino."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bk6JHolSJxSz"
      },
      "source": [
        "# <font color='blue'>Questão 3 </font>\n",
        "Complete as funções aqui descritas seguindo a assinatura sugerida\n",
        "\n",
        "Para separar em treino e teste, de uma olhada na função [train_test_split()](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.train_test_split.html) do Scikit-Learn"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gI5ggHUlJxS0"
      },
      "outputs": [],
      "source": [
        "def load_data(data_path='data/weatherAUS.csv')-> pd.DataFrame:\n",
        "    \"\"\"Funcao que importa dados de um arquivo csv, usando pandas\"\"\"\n",
        "    #Seu código aqui\n",
        "\n",
        "    return raw_data\n",
        "\n",
        "def pre_processing(raw_data:pd.DataFrame)-> pd.DataFrame:\n",
        "    \"\"\"Funcao que filtra e limpa os dados meteorologicos para o treinamento\"\"\"\n",
        "    #Seu código aqui\n",
        "\n",
        "    return processed_data\n",
        "\n",
        "\n",
        "def split_data(data:pd.DataFrame, val_size= 0.2)-> np.array:\n",
        "    \"\"\"Funcao que separa seus dados em teste e treino conforme a proporcao val_size\"\"\"\n",
        "    #Seu código aqui\n",
        "\n",
        "    return x_train, x_val, y_train, y_val\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ytKb1DlsJxS0"
      },
      "outputs": [],
      "source": [
        "df = load_data()\n",
        "df = pre_processing(df)\n",
        "visualize_data(df)\n",
        "x_train, x_val, y_train, y_val = split_data(df,)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2F0iWfJYJxS0"
      },
      "source": [
        "# <font color='blue'>Questão 4 </font>\n",
        "Agora que você ja ganhou uma familiaridade com a API Keras, escreva sozinho do começo ao fim um modelo que ira dizer se amanhã vai chover ou não e avalie sua performance.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "loD7lw_tJxS1"
      },
      "outputs": [],
      "source": [
        "# Seu código aqui"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": ".venv_tutorial",
      "language": "python",
      "name": ".venv_tutorial"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.5"
    },
    "colab": {
      "name": "Copy of 02 - NN & Backpropagation.ipynb",
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}